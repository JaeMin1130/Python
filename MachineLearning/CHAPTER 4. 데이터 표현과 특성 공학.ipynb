{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "import missingno as msno    # 누락값 표시\n",
    "import warnings\n",
    "import mglearn\n",
    "warnings.filterwarnings('ignore')  # 워닝 무시\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\ija06\\OneDrive\\바탕 화면\\파이썬 라이브러리를 활용한 머신러닝\\mglearn\\adult.data',\n",
    "header=None, index_col=False,\n",
    "names=['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "       'martial-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'occupation',\n",
    "'hours-per-week','income']]\n",
    "data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩\n",
    "data_dummies = pd.get_dummies(data)\n",
    "features = data_dummies.loc[:, 'age':'occupation_ Transport-moving']\n",
    "# Numpy 배열 추출\n",
    "X = features.values\n",
    "y = data_dummies['income_ >50K'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print('{:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구간 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=100)\n",
    "line = np.linspace(-3,3,1000, endpoint=False).reshape(-1,1) # X_test\n",
    "reg = LinearRegression().fit(X,y)\n",
    "plt.plot(line, reg.predict(line), '--', label='LinReg') \n",
    "reg = DecisionTreeRegressor(min_samples_split=3).fit(X,y)\n",
    "plt.plot(line, reg.predict(line), label='TreeReg') \n",
    "\n",
    "plt.plot(X[:,0], y, 'o', c='k')\n",
    "plt.ylabel('Reg output')\n",
    "plt.xlabel('input feature')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구간 분할(bining)\n",
    "\n",
    "bins = np.linspace(-3, 3, 11)\n",
    "which_bin = np.digitize(X, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(which_bin)\n",
    "X_binned = encoder.transform(which_bin)\n",
    "line_binned = encoder.transform(np.digitize(line, bins=bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 후 다시 모델링하기\n",
    "\n",
    "reg = LinearRegression().fit(X_binned, y)\n",
    "plt.plot(line, reg.predict(line_binned), '--', label='binned LinReg')\n",
    "reg = DecisionTreeRegressor(min_samples_split=3).fit(X_binned, y)\n",
    "plt.plot(line, reg.predict(line_binned), label='binned Tree')\n",
    "\n",
    "plt.plot(X[:,0], y, 'o', c='k')\n",
    "plt.vlines(bins, -3, 3, linewidth=1, alpha=.2)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Reg output')\n",
    "plt.xlabel('input Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상호작용 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구간특성(10) + 원본특성(1)\n",
    "X_combined = np.hstack([X,X_binned])\n",
    "reg = LinearRegression().fit(X_combined, y)\n",
    "line_combined = np.hstack([line, line_binned])\n",
    "plt.plot(line, reg.predict(line_combined), label='LinReg + Origin feature')\n",
    "\n",
    "for bin in bins:\n",
    "    plt.plot([bin, bin], [-3, 3], ':', c='k', linewidth=1)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Reg')\n",
    "plt.xlabel('Feat')\n",
    "plt.plot(X[:,0], y, 'o', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구간특성 + (구간특성*원래특성)\n",
    "\n",
    "X_product = np.hstack([X_binned, X * X_binned])\n",
    "reg = LinearRegression().fit(X_product, y)\n",
    "line_product = np.hstack([line_binned, line*line_binned])\n",
    "plt.plot(line, reg.predict(line_product), label='LinReg mul Oringin Feature')\n",
    "\n",
    "for bin in bins:\n",
    "    plt.plot([bin, bin], [-3,3], ':', c='k', linewidth=1)\n",
    "\n",
    "plt.plot(X[:,0], y, 'o', c='k')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Reg')\n",
    "plt.xlabel('Feat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다항식 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다항식 추가 선형 모델 VS svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# x**10까지 고차항을 추가한다.\n",
    "# 기본값인 'include_bias=True'는 절편을 위해 값이 1인 특성을 추가한다.\n",
    "poly = PolynomialFeatures(degree=10, include_bias=False)\n",
    "poly.fit(X)\n",
    "X_poly = poly.transform(X)\n",
    "poly.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항식을 추가한 선형 회귀\n",
    "reg = LinearRegression().fit(X_poly,y)\n",
    "line_poly = poly.transform(line)\n",
    "plt.plot(line, reg.predict(line_poly), label='mul square LinReg')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Reg')\n",
    "plt.xlabel('Feat')\n",
    "plt.plot(X[:,0], y, 'o', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본특성의 svm 모델 vs  다항식 선형 모델\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "for gamma in [1,10]:\n",
    "    svr = SVR(gamma=gamma).fit(X,y)\n",
    "    plt.plot(line, svr.predict(line), label='SVR gamma={}'.format(gamma))\n",
    "\n",
    "plt.plot(line, reg.predict(line_poly), label='mul square LinReg')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Reg')\n",
    "plt.xlabel('Feat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보스턴 주택 가격 데이터셋에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=0)\n",
    "\n",
    "#데이터 스케일 조정\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항식 특성 추가하기\n",
    "poly = PolynomialFeatures(degree=2).fit(X_train_scaled)\n",
    "X_train_poly = poly.transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "print('\\n{}'.format(poly.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge로 비교하기(원본 특성 vs 다항식 추가)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(X_train_scaled, y_train)\n",
    "print('{:.2f}'.format(ridge.score(X_test_scaled, y_test)))\n",
    "ridge = Ridge().fit(X_train_poly, y_train)\n",
    "print('{:.2f}'.format(ridge.score(X_test_poly, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일변량 비선형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카운트 데이터 만들기\n",
    "rnd = np.random.RandomState(0)\n",
    "X_org = rnd.normal(size=(1000,3))\n",
    "w = rnd.normal(size=3)\n",
    "y = np.dot(X_org, w) # (1000 X 3)*(3 X 1) = (1000 X 1) array\n",
    "\n",
    "# 푸아송 분포의 데이터 만들기\n",
    "X = rnd.poisson(10*np.exp(X_org))\n",
    "'\\n{}'.format(np.bincount(X[:,0]))\n",
    "\n",
    "# X[0]의 히스토그램\n",
    "bins = np.bincount(X[:,0])\n",
    "plt.bar(range(len(bins)), bins, color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X에 Ridge 회귀 적용하기\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "score = Ridge().fit(X_train, y_train).score(X_test, y_test)\n",
    "print('{:.3f}'.format(score))\n",
    "\n",
    "# X를 log 스케일로 변환하기\n",
    "X_train_log = np.log(X_train + 1)\n",
    "X_test_log = np.log(X_test + 1) \n",
    "plt.hist(X_train_log[:,0], bins=25, color='grey')\n",
    "plt.show()\n",
    "\n",
    "# 다시 Ridge 적용하기\n",
    "score = Ridge().fit(X_train_log, y_train).score(X_test_log, y_test)\n",
    "print('{:.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 자동 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 일변량 통계(univariate statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 고정된 난수를 발생합니다.\n",
    "rng = np.random.RandomState(42)\n",
    "noise = rng.normal(size=(len(cancer.data), 50))\n",
    "# 데이터에 노이즈 특성을 추가한다.\n",
    "X_w_noise = np.hstack([cancer.data, noise])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w_noise, cancer.target, \n",
    "                                                    random_state=0, test_size=.5)\n",
    "# f_classif(기본값)와 SelectPercentile을 사용하여 특성의 50%를 선택한다.\n",
    "select = SelectPercentile(percentile=50)\n",
    "select.fit(X_train, y_train)\n",
    "X_train_selected = select.transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_selected.shape)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_support()로 선택된 특성 확인하기\n",
    "mask = select.get_support()\n",
    "print(mask)\n",
    "plt.matshow(mask.reshape(1,-1), cmap='gray_r')\n",
    "plt.xlabel('Feature num')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 특성(80) VS 선택 특성(40) : LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('{:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print('{:.3f}'.format(lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(select.pvalues_)\n",
    "print(select.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 기반 선택(model-based selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "select = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
    "select.fit(X_train, y_train)\n",
    "X_train_l1 = select.transform(X_train)\n",
    "\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1,-1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_l1 = select.transform(X_test)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print('{:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "lr.fit(X_train_l1, y_train)\n",
    "print('{:.3f}'.format(lr.score(X_test_l1, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 반복적 선택(iterative selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "             n_features_to_select=40)\n",
    "select.fit(X_train, y_train)\n",
    "X_train_rfe = select.transform(X_train)\n",
    "\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1,-1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rfe = select.transform(X_test)\n",
    "\n",
    "select.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 지식을 활용한 특성공학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike = mglearn.datasets.load_citibike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8월 한 달 동안의 대여 횟수를 그래프로 나타내기\n",
    "plt.figure(figsize=(10,3))\n",
    "xticks = pd.date_range(start=citibike.index.min(), end=citibike.index.max(), freq='D')\n",
    "week = ['sun', 'mon', 'thue', 'wedn', 'thur', 'fri', 'sat']\n",
    "xticks_name = [week[int(w)]+ d for w, d in zip(xticks.strftime('%w'),\n",
    "                                              xticks.strftime('%m-%d'))]\n",
    "plt.xticks(xticks, xticks_name, rotation=90, ha='left')\n",
    "plt.plot(citibike, linewidth=1)\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('lental freq')\n",
    "\n",
    "'''이와 같은 시계열 데이터를 이용한 예측작업은 \n",
    "과거 데이터(train)에서 학습하여 미래(test)를 예측하는 방식을 사용한다.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSIX 시간을 특성으로 했을 때 예측\n",
    "\n",
    "# 타깃값(대여 횟수) 추출\n",
    "y = citibike.values\n",
    "# POSIX 시간을 10**9로 나누어 변환\n",
    "X = citibike.index.astype('int64').values.reshape(-1,1) // 10**9\n",
    "\n",
    "n_train = 184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 특성을 사용하여 평가하고 그래프를 그린다.\n",
    "def eval_on_features(features, target, regressor):\n",
    "    X_train, X_test = features[:n_train], features[n_train:] \n",
    "    y_train, y_test = target[:n_train], target[n_train:] \n",
    "    \n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.xticks(range(0, len(X), 8), xticks_name, rotation=90, ha='left')\n",
    "\n",
    "    plt.plot(range(n_train), y_train, label='train')\n",
    "    plt.plot(range(n_train, len(y_test) + n_train), y_test, '-', label='test')\n",
    "    \n",
    "    plt.plot(range(n_train), y_pred_train, '--', label='train_pred')\n",
    "    plt.plot(range(n_train, len(y_test) + n_train), y_pred, '--', label='test_pred')\n",
    "\n",
    "    plt.legend(loc=(1.01, 0))\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('lental freq')\n",
    "    \n",
    "    print('test r^2 : {:.2f}'.format(regressor.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 포레스트는 데이터 전처리가 거의 필요하지 않아 맨 처음 시도해보기 좋은 모델이다.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "eval_on_features(X, y, regressor)\n",
    "\n",
    "'''R^2는 -0.04로 거의 학습되지 않았다.\n",
    "-> 트리 모델은 훈련 세트에 있는 특성의 범위 밖으로 외삽할 수 없다.\n",
    "-> 마지막 훈련 세트 데이터의 타깃값을 예측으로 사용한다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간을 특성으로 예측\n",
    "X_hour = citibike.index.hour.values.reshape(-1,1)\n",
    "eval_on_features(X_hour, y, regressor)\n",
    "\n",
    "# 요일 정보 추가했을 때 예측\n",
    "X_hour_week = np.hstack([citibike.index.dayofweek.values.reshape(-1,1),\n",
    "                        citibike.index.hour.values.reshape(-1,1)])\n",
    "eval_on_features(X_hour_week, y, regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형 모델로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegressor 적용하기\n",
    "from sklearn.linear_model import LinearRegression\n",
    "eval_on_features(X_hour_week, y, LinearRegression())\n",
    "\n",
    "'''요일과 시간이 정수로 인코딩되어 있어서 연속형 변수로 해석되기 때문에 성능이 좋지 않다.\n",
    "   선형 모델은 시간을 선형 함수로만 학습할 수 있어서, 하루에서 시간이 흐를수록 대여 수가 늘어나게 학습되었다.'''\n",
    "\n",
    "# OneHotEncoder로 정수형을 범주형으로 바꾸기\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X_hour_week_onehot = enc.fit_transform(X_hour_week).toarray()\n",
    "eval_on_features(X_hour_week_onehot, y, LinearRegression())\n",
    "\n",
    "'''이 선형 모델은 요일마다 하나의 계수를 학습하고, 시간마다도 하나의 계수를 학습한다.\n",
    "   이 말은 시간 패턴이 모든 날에 걸쳐 공유된다는 뜻이다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상호작용 특성을 사용하여 시간과 요일의 조합별 계수를 학습하기\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True,\n",
    "                                            include_bias=False)\n",
    "X_hour_week_onehot_poly = poly.fit_transform(X_hour_week_onehot)\n",
    "lr = Ridge() \n",
    "eval_on_features(X_hour_week_onehot_poly, y, lr)           \n",
    "\n",
    "'''랜텀 포레스트와 달리 무엇이 학습되었는지가 명확하다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = ['%02d:00' % i for i in range(0, 24, 3)]\n",
    "day = ['mon', 'thue', 'wedn', 'thur', 'fri', 'sat', 'sun']\n",
    "features = day + hour\n",
    "\n",
    "# get_feature_names 메서드로 상호작용 특성에 이름을 달고, 계수가 0이 아닌 특성만 선택한다.\n",
    "features_poly = poly.get_feature_names(features)\n",
    "features_nonzero = np.array(features_poly)[lr.coef_ != 0]\n",
    "coef_nonzero = lr.coef_[lr.coef_ != 0]\n",
    "\n",
    "# 모델이 학습한 계수를 그래프로 나타내기\n",
    "plt.figure(figsize=(15,2))\n",
    "plt.plot(coef_nonzero, 'o')\n",
    "plt.xticks(np.arange(len(coef_nonzero)), features_nonzero, rotation=90)\n",
    "plt.ylabel('coefficient volume')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fa4360fac3e96b45dfbe1673664e4bea8b8cb4d6cd41c4e45be64e581f59653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
