{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests 모듈\n",
    "requests 모듈은 HTTP 요청을 보내고, 응답을 받는 기능을 제공합니다.<br>\n",
    "즉, 웹 사이트의 HTML 코드를 가져오는 데 사용됩니다. \n",
    "\n",
    "### bs4 모듈\n",
    "bs4 모듈은 HTML, XML 등의 문서에서 데이터를 추출하는 기능을 제공합니다.<br> \n",
    "즉, 웹 사이트에서 필요한 정보를 가져오는 데 사용됩니다.<br> \n",
    "HTML 태그를 이용하여 원하는 정보를 선택할 수 있으며, 정규 표현식 등을 이용하여 문자열을 검색할 수도 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.hani.co.kr/arti/list.html?sec=news&subsec=politics\"\n",
    "response = requests.get(url)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup()는 HTML, XML 등의 문서를 파싱하여 파이썬에서 사용할 수 있는 객체로 만드는 클래스입니다.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<body>\n",
    "<div class=\"menu\">\n",
    "    <ul>\n",
    "        <li><a href=\"/home\">Home</a></li>\n",
    "        <li><a href=\"/about\">About</a></li>\n",
    "        <li><a href=\"/contact\">Contact</a></li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"content\">\n",
    "    <h1>Hello, World!</h1>\n",
    "    <p>This is an example of using Beautifulsoup.</p>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find() 메서드 사용 예시\n",
    "div_menu = soup.find('div', {'class': 'menu'})\n",
    "print(div_menu)\n",
    "\n",
    "# find_all() 메서드 사용 예시\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<body>\n",
    "<div class=\"menu\">\n",
    "    <ul>\n",
    "        <li><a href=\"/home\">Home</a></li>\n",
    "        <li><a href=\"/about\">About</a></li>\n",
    "        <li><a href=\"/contact\">Contact</a></li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"content\">\n",
    "    <h1>Hello, World!</h1>\n",
    "    <p>This is an example of using Beautifulsoup.</p>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# CSS 선택자를 이용하여 태그 선택하기\n",
    "menu = soup.select('.menu')\n",
    "for m in menu:\n",
    "    print(m)\n",
    "\n",
    "# 복합 CSS 선택자를 이용하여 태그 선택하기\n",
    "links = soup.select('div.menu a')\n",
    "for link in links:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <h1>제목</h1>\n",
    "        <p class=\"content\">내용 1</p>\n",
    "        <p class=\"content\">내용 2</p>\n",
    "        <a href=\"http://www.example.com\">링크</a>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# select_one() 메서드 사용 예시\n",
    "title_tag = soup.select_one('h1')\n",
    "print(type(title_tag))  # <class 'bs4.element.Tag'>\n",
    "print(title_tag.text)   # 제목\n",
    "\n",
    "link_tag = soup.select_one('a')\n",
    "print(type(link_tag))   # <class 'bs4.element.Tag'>\n",
    "print(link_tag.text)    # 링크\n",
    "\n",
    "# select() 메서드 사용 예시\n",
    "content_tags = soup.select('.content')\n",
    "print(type(content_tags))  # <class 'bs4.element.ResultSet'>\n",
    "for content_tag in content_tags:\n",
    "    print(content_tag.text)  # 내용 1, 내용 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "<body>\n",
    "<div class=\"menu\">\n",
    "    <ul>\n",
    "        <li><a href=\"/home\">Home</a></li>\n",
    "        <li><a href=\"/about\">About</a></li>\n",
    "        <li><a href=\"/contact\">Contact</a></li>\n",
    "    </ul>\n",
    "</div>\n",
    "<div class=\"content\">\n",
    "    <h1>Hello, World!</h1>\n",
    "    <p>This is an example of using Beautifulsoup.</p>\n",
    "    <a href=\"https://www.google.com\" target=\"_blank\">Google</a>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# text() 메서드 사용 예시\n",
    "h1 = soup.find('h1')\n",
    "print(h1.text)\n",
    "\n",
    "# get() 메서드 사용 예시\n",
    "a = soup.find('a')\n",
    "print(a.get('href'))\n",
    "print(a.get('target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 네이버 블로그에서 키워드 \"파이썬\"에 대한 포스트 검색 페이지에서 HTML 코드 가져오기\n",
    "url = 'https://search.naver.com/search.naver'\n",
    "params = {'query': '파이썬', 'where': 'blog'}\n",
    "response = requests.get(url, params=params)\n",
    "#print(response.url)\n",
    "\n",
    "# HTML 코드 파싱하기\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 포스트 정보 태그 가져오기\n",
    "posts = soup.select('.total_tit')\n",
    "\n",
    "# 포스트 정보 출력하기\n",
    "for post in posts:\n",
    "    # 제목과 링크 가져오기\n",
    "    title = post.text\n",
    "    link = post.get('href')\n",
    "    print(title)\n",
    "    print(link)\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.google.com/topstories?hl=ko&gl=KR&ceid=KR:ko'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "titles = soup.select('.WwrzSb')\n",
    "for title in titles:\n",
    "    print(title.get('aria-label'))\n",
    "    print('https://news.google.com' + title['href'][1:])\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 다음 영화 예매 순위 정보를 출력하는 예시\n",
    "\n",
    "url = 'https://movie.daum.net/ranking/reservation'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "rank_list = soup.select('div.thumb_cont > strong > a')\n",
    "rank_rate = soup.select('span.txt_append > span > span')\n",
    "\n",
    "print(rank_list)\n",
    "# for rank, title in enumerate(rank_list, 1):\n",
    "#     print(f'{rank}위: {title.text} / 평점({rank_rate[(rank - 1) * 2].text}) / 예매율({rank_rate[2 * rank - 1].text})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
